{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Méthodes d'Ensembles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from prepdata import *\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143072.78194\n",
      "53\n"
     ]
    }
   ],
   "source": [
    "# Récupérer les données du dataset abalone8\n",
    "X, y = data_recovery(\"abalone8\")\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "print(np.sum(X))\n",
    "print(np.sum(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing SVM with C = 0.01\n",
      "Mean cross-validated accuracy for C=0.01: 0.9672\n",
      "Testing SVM with C = 0.1\n",
      "Mean cross-validated accuracy for C=0.1: 0.9672\n",
      "Testing SVM with C = 1.0\n",
      "Mean cross-validated accuracy for C=1.0: 0.9672\n",
      "Testing SVM with C = 10.0\n",
      "Mean cross-validated accuracy for C=10.0: 0.9672\n",
      "Testing SVM with C = 100.0\n",
      "Mean cross-validated accuracy for C=100.0: 0.9672\n",
      "\n",
      "Best C: 0.01 with cross-validated accuracy: 0.9672\n"
     ]
    }
   ],
   "source": [
    "# Initialisation de StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Liste de différents C (lambda = 1 / C) à tester\n",
    "C_values = [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "\n",
    "# Stocker les résultats d'accuracy pour chaque valeur de C\n",
    "best_C = None\n",
    "best_accuracy = 0\n",
    "C_accuracy_scores = {}\n",
    "\n",
    "# Parcours de chaque valeur de C\n",
    "for C in C_values:\n",
    "    print(f\"Testing SVM with C = {C}\")\n",
    "    \n",
    "    accuracy_scores = []  # Stocker les scores d'accuracy pour chaque fold\n",
    "    \n",
    "    # Parcours des folds pour la cross-validation\n",
    "    for train_index, val_index in skf.split(X_train, y_train):\n",
    "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "        \n",
    "        # Normalisation sur les k-1 folds (uniquement les données d'entraînement)\n",
    "        scaler = Normalizer()\n",
    "        X_train_fold = scaler.fit_transform(X_train_fold)\n",
    "        \n",
    "        # Normaliser les données du fold de validation avec les paramètres du train_fold\n",
    "        X_val_fold = scaler.transform(X_val_fold)\n",
    "        \n",
    "        # Initialiser le modèle SVM avec kernel linéaire pour cette valeur de C\n",
    "        clf = SVC(C=C, kernel='linear')\n",
    "        \n",
    "        # Entraînement du modèle sur le fold courant\n",
    "        clf.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # Prédiction sur les données de validation\n",
    "        y_pred_fold = clf.predict(X_val_fold)\n",
    "        \n",
    "        # Calcul de l'accuracy sur le fold de validation\n",
    "        accuracy = accuracy_score(y_val_fold, y_pred_fold)\n",
    "        accuracy_scores.append(accuracy)\n",
    "\n",
    "    # Calcul de l'accuracy moyenne pour cette valeur de C\n",
    "    mean_accuracy = np.mean(accuracy_scores)\n",
    "    C_accuracy_scores[C] = mean_accuracy\n",
    "    \n",
    "    print(f\"Mean cross-validated accuracy for C={C}: {mean_accuracy:.4f}\")\n",
    "    \n",
    "    # Mettre à jour le meilleur C en fonction de l'accuracy\n",
    "    if mean_accuracy > best_accuracy:\n",
    "        best_accuracy = mean_accuracy\n",
    "        best_C = C\n",
    "\n",
    "# Afficher le meilleur C et son accuracy\n",
    "print(f\"\\nBest C: {best_C} with cross-validated accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with best C=0.01: 0.9656\n"
     ]
    }
   ],
   "source": [
    "# Entraînement du modèle final avec le meilleur C sur l'ensemble complet d'entraînement\n",
    "scaler = Normalizer()  # Normalisation pour le modèle final\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "clf_final = SVC(C=best_C, kernel='linear')\n",
    "clf_final.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction finale sur l'ensemble de test\n",
    "y_test_pred = clf_final.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Test accuracy with best C={best_C}: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[309   0]\n",
      " [ 11   0]]\n"
     ]
    }
   ],
   "source": [
    "# Affichage de la matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
